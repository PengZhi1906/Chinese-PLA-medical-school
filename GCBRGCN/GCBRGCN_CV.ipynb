{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[88, 213], [101, 166], [88, 122], [306, 134], [306, 134], [306, 130], [306, 130], [337, 432], [303, 107], [303, 217], [257, 144], [368, 114], [368, 433], [352, 126], [364, 198], [364, 198], [329, 162], [369, 170], [84, 154], [103, 118], [103, 118], [370, 176], [332, 176], [370, 176], [332, 176], [371, 147], [371, 147], [364, 432], [364, 432], [257, 112], [372, 111], [73, 106], [265, 434], [373, 435], [373, 435], [373, 435], [373, 435], [374, 143], [374, 143], [16, 204], [20, 171], [375, 178], [84, 149], [88, 127], [89, 105], [89, 105], [101, 166], [101, 127], [376, 136], [377, 160], [250, 145], [257, 126], [259, 176], [265, 149], [265, 149], [268, 122], [277, 151], [277, 436], [285, 200], [304, 149], [307, 184], [307, 184], [307, 184], [307, 184], [378, 126], [323, 205], [325, 437], [325, 140], [326, 126], [326, 126], [326, 126], [352, 126], [355, 435], [355, 208], [364, 133], [379, 128], [46, 126], [88, 446], [380, 128], [381, 112], [374, 122], [382, 206], [383, 128], [257, 144], [257, 155], [257, 118], [265, 214], [276, 167], [303, 107], [303, 217], [306, 130], [306, 130], [306, 134], [325, 438], [329, 162], [330, 432], [342, 176], [351, 209], [352, 126], [352, 178], [364, 198], [364, 198], [384, 128], [385, 128], [386, 128], [387, 439], [369, 170], [6, 155], [6, 155], [388, 220], [388, 188], [374, 141], [374, 142], [374, 143], [16, 440], [372, 111], [389, 155], [389, 155], [390, 155], [390, 155], [73, 106], [73, 106], [84, 154], [88, 213], [88, 213], [88, 213], [101, 115], [101, 115], [88, 149], [88, 149], [88, 149], [88, 149], [371, 147], [352, 125], [391, 155], [355, 157], [364, 432], [101, 169], [101, 169], [101, 130], [101, 166], [103, 118], [392, 155], [393, 441], [393, 441], [393, 441], [393, 441], [393, 441], [393, 441], [393, 441], [393, 441], [394, 155], [257, 112], [265, 122], [265, 442], [265, 127], [248, 106], [346, 443], [395, 182], [100, 212], [396, 116], [241, 163], [74, 444], [292, 174], [292, 183], [292, 124], [260, 445], [344, 446], [344, 465], [344, 448], [344, 449], [344, 450], [344, 451], [344, 452], [344, 453], [92, 107], [92, 106], [55, 107], [55, 454], [55, 113], [55, 179], [92, 107], [92, 455], [92, 432], [92, 106], [300, 112], [28, 454], [28, 455], [260, 445], [344, 449], [344, 451], [347, 449], [347, 451], [300, 112], [55, 454], [55, 113], [55, 218], [344, 446], [344, 465], [344, 448], [344, 449], [344, 450], [344, 451], [344, 452], [344, 453], [260, 445], [28, 455], [319, 109], [292, 448], [292, 445], [292, 108], [292, 110], [292, 124], [349, 456], [349, 106], [344, 446], [344, 465], [344, 448], [344, 449], [344, 450], [344, 451], [344, 452], [344, 453], [344, 108], [101, 115], [88, 159], [88, 159], [88, 159], [88, 159], [270, 207], [91, 130], [364, 168], [397, 215], [20, 129], [398, 131], [90, 219], [399, 155], [88, 201], [244, 177], [72, 191], [243, 145], [240, 125], [400, 433], [287, 126], [401, 137], [402, 457], [102, 159], [403, 184], [285, 199], [324, 132], [298, 141], [404, 152], [257, 161], [405, 458], [406, 168], [92, 459], [53, 460], [407, 461], [408, 164], [408, 164], [7, 196], [24, 217], [409, 181], [410, 220], [410, 220], [411, 120], [411, 120], [48, 123], [70, 186], [412, 106], [413, 454], [413, 169], [91, 139], [92, 157], [414, 153], [415, 189], [227, 187], [233, 192], [235, 159], [238, 124], [238, 124], [245, 173], [247, 156], [252, 462], [253, 198], [254, 463], [416, 149], [416, 208], [416, 156], [285, 157], [285, 113], [291, 464], [291, 464], [324, 194], [324, 117], [324, 194], [324, 117], [327, 172], [328, 145], [331, 169], [343, 123], [348, 111], [355, 461], [364, 465], [25, 175], [417, 195], [59, 135], [92, 107], [92, 201], [92, 158], [418, 185], [101, 128], [235, 190], [237, 126], [419, 119], [274, 123], [344, 115], [420, 153], [246, 210], [262, 463], [421, 160], [422, 203], [239, 455], [421, 160], [422, 203], [239, 455], [423, 216], [424, 193], [425, 215], [242, 138], [426, 121], [285, 160], [285, 160], [427, 148], [269, 153], [428, 211], [312, 206], [222, 138], [429, 202], [430, 180], [251, 466], [354, 463], [388, 434], [388, 434], [56, 160], [327, 165], [431, 186], [355, 126], [3, 146], [285, 123], [364, 432], [249, 136], [91, 122]]\n",
      "Graph(num_nodes={'rna': 493},\n",
      "      num_edges={('rna', 'type1', 'rna'): 353, ('rna', 'type2', 'rna'): 354},\n",
      "      metagraph=[('rna', 'rna', 'type1'), ('rna', 'rna', 'type2')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_29776\\3235661770.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  name = x.loc[i][0]\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_29776\\3235661770.py:56: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  start = adj.loc[i][0]\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_29776\\3235661770.py:57: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  mid = adj.loc[i][1]\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_29776\\3235661770.py:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  end = adj.loc[i][2]\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model import RGCN_NET\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    \"\"\"\n",
    "    fix the random seed\n",
    "    :param seed: the random seed\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    return None\n",
    "\n",
    "setup_seed(4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# attribute\n",
    "name2id = {}\n",
    "id2name = {}\n",
    "\n",
    "\n",
    "x = pd.read_csv(\"data/features.csv\")\n",
    "\n",
    "for i in range(len(x)):\n",
    "    name = x.loc[i][0]\n",
    "    id2name[i] = name\n",
    "    name2id[name] = i\n",
    "\n",
    "x = x.iloc[:, 1:]\n",
    "x = x.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "adj = pd.read_csv(\"data/Network.csv\")\n",
    "\n",
    "max_id = x.shape[0]\n",
    "edges_1 = []\n",
    "edges_2 = []\n",
    "for i in range(len(adj)):\n",
    "    start = adj.loc[i][0]\n",
    "    mid = adj.loc[i][1]\n",
    "    end = adj.loc[i][2]\n",
    "    # if start != \"NA\":\n",
    "    #     try:\n",
    "    #         name2id[start]\n",
    "    #     except:\n",
    "    #         name2id[start] = max_id\n",
    "    #         id2name[max_id] = start\n",
    "    #         max_id += 1\n",
    "    #\n",
    "    # if mid != \"NA\":\n",
    "    #     try:\n",
    "    #         name2id[mid]\n",
    "    #     except:\n",
    "    #         name2id[mid] = max_id\n",
    "    #         id2name[max_id] = mid\n",
    "    #         max_id += 1\n",
    "    #\n",
    "    # if end != \"NA\":\n",
    "    #     try:\n",
    "    #         name2id[end]\n",
    "    #     except:\n",
    "    #         name2id[end] = max_id\n",
    "    #         id2name[max_id] = end\n",
    "    #         max_id += 1\n",
    "\n",
    "    if 1:\n",
    "        try:\n",
    "            # 1\n",
    "            edges_1.append([name2id[start], name2id[mid]])\n",
    "        except:\n",
    "            pass\n",
    "        # try:\n",
    "        #     edges_1.append([name2id[mid], name2id[start]])\n",
    "        # except:\n",
    "        #     pass\n",
    "    if 1:\n",
    "        try:\n",
    "            edges_2.append([name2id[mid], name2id[end]])\n",
    "        except:\n",
    "            pass\n",
    "        # try:\n",
    "        #     edges_2.append([name2id[end], name2id[mid]])\n",
    "        # except:\n",
    "        #     pass\n",
    "\n",
    "\n",
    "\n",
    "label = pd.read_csv(\"data/label.csv\")\n",
    "# final 0.6936936936936937\n",
    "\n",
    "\n",
    "\n",
    "y = np.zeros((x.shape[0], ))\n",
    "for i in range(len(label[\"node\"])):\n",
    "    try:\n",
    "        index = name2id[label[\"node\"].iloc[i]]\n",
    "        y[index] = label[\"label\"].iloc[i]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "y = torch.tensor(y).float()\n",
    "#print(y)\n",
    "\n",
    "# x = np.concatenate([x, np.zeros((len(name2id)-x.shape[0], 5))], axis=0)\n",
    "x = torch.tensor(x).float()\n",
    "\n",
    "print(edges_1)\n",
    "g = dgl.heterograph(\n",
    "    {\n",
    "        ('rna', 'type1', 'rna'): edges_1,\n",
    "        ('rna', 'type2', 'rna'): edges_2\n",
    "    }\n",
    ")\n",
    "\n",
    "print(g)\n",
    "\n",
    "# logits = rgcn_net(None, None)\n",
    "# y_pred = (logits >= 0.5).int().squeeze(dim=-1)\n",
    "\n",
    "# acc = accuracy_score(y[test_id], y_pred[test_id])\n",
    "# print(acc)\n",
    "\n",
    "# print(emb[\"inc_rna\"].shape)\n",
    "# print(emb[\"m_rna\"].shape)\n",
    "\n",
    "#\n",
    "# GCN\n",
    "\n",
    "idx = list(range(x.shape[0]))\n",
    "random.shuffle(idx)\n",
    "idx = np.array(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182\n",
      "acc 0.8181818181818182\n",
      "precision 0.5833333333333334\n",
      "recall 0.6363636363636364\n",
      "f1-score 0.6086956521739131\n",
      "auc 0.7532467532467532\n",
      "#####\n",
      "0.7777777777777778\n",
      "acc 0.7777777777777778\n",
      "precision 0.7755102040816326\n",
      "recall 1.0\n",
      "f1-score 0.8735632183908045\n",
      "auc 0.5217391304347826\n",
      "#####\n",
      "0.797979797979798\n",
      "acc 0.797979797979798\n",
      "precision 0.7419354838709677\n",
      "recall 0.92\n",
      "f1-score 0.8214285714285714\n",
      "auc 0.7967346938775511\n",
      "#####\n",
      "0.5612244897959183\n",
      "acc 0.5612244897959183\n",
      "precision 0.32727272727272727\n",
      "recall 0.75\n",
      "f1-score 0.4556962025316456\n",
      "auc 0.625\n",
      "#####\n",
      "0.5714285714285714\n",
      "acc 0.5714285714285714\n",
      "precision 0.43243243243243246\n",
      "recall 1.0\n",
      "f1-score 0.6037735849056604\n",
      "auc 0.6818181818181819\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "kf = KFold(n_splits=5,shuffle=False)  # 初始化KFold\n",
    "for train_id, test_id in kf.split(x):\n",
    "    #print('train_index:%s , test_index: %s ' %(train_id, test_id))\n",
    "\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    rgcn_net = RGCN_NET(g, 400, 1, dropout=0)\n",
    "    optimizer = torch.optim.Adam(rgcn_net.parameters(), lr=1 * 1e-2)\n",
    "\n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "    threshold = 0.3\n",
    "    best_logit = 0\n",
    "    for epoch in range(100):\n",
    "        rgcn_net.eval()\n",
    "        logits = rgcn_net(None, None)\n",
    "\n",
    "        y_pred = (logits >= threshold).int().squeeze(dim=-1)\n",
    "        acc = accuracy_score(y[test_id], y_pred[test_id])\n",
    "        #print(acc)\n",
    "        if best_acc < acc:\n",
    "            best_acc = acc\n",
    "            best_model = copy.deepcopy(rgcn_net)\n",
    "\n",
    "        rgcn_net.train()\n",
    "        logits = rgcn_net(None, None)\n",
    "        loss = criterion(logits.squeeze(dim=-1)[train_id], y[train_id])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    print(best_acc)\n",
    "    best_model.eval()\n",
    "    logits = best_model(None, None)\n",
    "\n",
    "    y_pred = (logits >= threshold).int().squeeze(dim=-1)\n",
    "    acc = accuracy_score(y[test_id], y_pred[test_id])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    logits = best_model(None, None)\n",
    "    y_pred = (logits >= threshold).int().squeeze(dim=-1)\n",
    "    logits_list = logits[test_id][:, 0].data\n",
    "    index = sorted(range(len(logits_list)), key=lambda k: logits_list[k], reverse=True)\n",
    "    # print(y_pred[index])\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y[test_id], y_pred[test_id])\n",
    "\n",
    "\n",
    "    acc = accuracy_score(y[test_id], y_pred[test_id])\n",
    "    print(\"acc\", acc)\n",
    "\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, classification_report\n",
    "\n",
    "    y_true = y[test_id]\n",
    "    y_pred = y_pred[test_id]\n",
    "    # 1.计算混淆矩阵\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # cm = np.array([[40, 24],\n",
    "    #  [ 9, 38]])\n",
    "\n",
    "    conf_matrix = pd.DataFrame(cm, index=['0', '1'], columns=['0', '1'])  # 数据有5个类别\n",
    "\n",
    "\n",
    "    #\n",
    "    # # 2.计算accuracy\n",
    "    # print('accuracy_score', accuracy_score(y_true, y_pred))\n",
    "    #\n",
    "    # # 3.计算多分类的precision、recall、f1-score分数\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    print('precision', precision_score(y_true, y_pred))\n",
    "    print('recall', recall_score(y_true, y_pred))\n",
    "    print('f1-score', f1_score(y_true, y_pred))\n",
    "    print('auc', auc)\n",
    "    print('#####')\n",
    "\n",
    "    #\n",
    "    # # 下面这个可以显示出每个类别的precision、recall、f1-score。\n",
    "    # print('classification_report\\n', classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
