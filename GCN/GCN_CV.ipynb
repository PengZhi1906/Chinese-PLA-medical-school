{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_27976\\2426522859.py:34: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  name = x.loc[i][0]\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_27976\\2426522859.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  start = adj.loc[i][0]\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_27976\\2426522859.py:49: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  mid = adj.loc[i][1]\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_27976\\2426522859.py:50: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  end = adj.loc[i][2]\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model import GCN_NET\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    \"\"\"\n",
    "    fix the random seed\n",
    "    :param seed: the random seed\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    return None\n",
    "\n",
    "setup_seed(0)\n",
    "\n",
    "# attribute\n",
    "name2id = {}\n",
    "id2name = {}\n",
    "x = pd.read_csv(\"data/features.csv\")\n",
    "\n",
    "for i in range(len(x)):\n",
    "    name = x.loc[i][0]\n",
    "    id2name[i] = name\n",
    "    name2id[name] = i\n",
    "\n",
    "x = x.iloc[:, 1:]\n",
    "x = x.to_numpy()\n",
    "\n",
    "# attribute\n",
    "# adj = pd.read_excel(\"adj.xlsx\")\n",
    "adj = pd.read_csv(\"data/Network.csv\")\n",
    "\n",
    "max_id = x.shape[0]\n",
    "edges = []\n",
    "for i in range(len(adj)):\n",
    "    start = adj.loc[i][0]\n",
    "    mid = adj.loc[i][1]\n",
    "    end = adj.loc[i][2]\n",
    "    # if start != \"NA\":\n",
    "    #     try:\n",
    "    #         name2id[start]\n",
    "    #     except:\n",
    "    #         name2id[start] = max_id\n",
    "    #         id2name[max_id] = start\n",
    "    #         max_id += 1\n",
    "    #\n",
    "    # if mid != \"NA\":\n",
    "    #     try:\n",
    "    #         name2id[mid]\n",
    "    #     except:\n",
    "    #         name2id[mid] = max_id\n",
    "    #         id2name[max_id] = mid\n",
    "    #         max_id += 1\n",
    "    #\n",
    "    # if end != \"NA\":\n",
    "    #     try:\n",
    "    #         name2id[end]\n",
    "    #     except:\n",
    "    #         name2id[end] = max_id\n",
    "    #         id2name[max_id] = end\n",
    "    #         max_id += 1\n",
    "\n",
    "    if 1:\n",
    "        try:\n",
    "            edges.append([name2id[start], name2id[mid]])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            edges.append([name2id[mid], name2id[start]])\n",
    "        except:\n",
    "            pass\n",
    "    if 1:\n",
    "        try:\n",
    "            edges.append([name2id[mid], name2id[end]])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            edges.append([name2id[end], name2id[mid]])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "label = pd.read_csv(\"data/label.csv\")\n",
    "\n",
    "y = np.zeros((x.shape[0], ))\n",
    "for i in range(len(label[\"node\"])):\n",
    "    try:\n",
    "        index = name2id[label[\"node\"].iloc[i]]\n",
    "        y[index] = label[\"label\"].iloc[i]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "y = torch.tensor(y).float()\n",
    "\n",
    "# x = np.concatenate([x, np.zeros((len(name2id)-x.shape[0], 5))], axis=0)\n",
    "\n",
    "x = torch.tensor(x).float()\n",
    "# print(x.shape)\n",
    "# print(len(id2name))\n",
    "# print(len(name2id))\n",
    "g = dgl.graph(edges)\n",
    "# print(g.nodes().shape)\n",
    "\n",
    "# print(x.shape)\n",
    "# print(g)\n",
    "\n",
    "# GCN\n",
    "criterion = torch.nn.BCELoss()\n",
    "net = GCN_NET()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-1)\n",
    "\n",
    "idx = list(range(x.shape[0]))\n",
    "random.shuffle(idx)\n",
    "idx = np.array(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492 493\n"
     ]
    }
   ],
   "source": [
    "print(len(label),len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = net(g, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "kf = KFold(n_splits=5,shuffle=False)  # 初始化KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6464646464646465\n",
      "final 0.6464646464646465\n",
      "final 0.6464646464646465\n",
      "precision 0.25925925925925924\n",
      "recall 0.3181818181818182\n",
      "f1-score 0.2857142857142857\n",
      "auc 0.6056670602125148\n",
      "###\n",
      "0.7676767676767676\n",
      "final 0.7676767676767676\n",
      "final 0.7676767676767676\n",
      "precision 0.7789473684210526\n",
      "recall 0.9736842105263158\n",
      "f1-score 0.8654970760233919\n",
      "auc 0.677345537757437\n",
      "###\n",
      "0.5252525252525253\n",
      "final 0.5252525252525253\n",
      "final 0.5252525252525253\n",
      "precision 0.5154639175257731\n",
      "recall 1.0\n",
      "f1-score 0.6802721088435374\n",
      "auc 0.6591836734693879\n",
      "###\n",
      "0.24489795918367346\n",
      "final 0.24489795918367346\n",
      "final 0.24489795918367346\n",
      "precision 0.24489795918367346\n",
      "recall 1.0\n",
      "f1-score 0.39344262295081966\n",
      "auc 0.6117680180180181\n",
      "###\n",
      "0.3469387755102041\n",
      "final 0.3469387755102041\n",
      "final 0.3469387755102041\n",
      "precision 0.3333333333333333\n",
      "recall 1.0\n",
      "f1-score 0.5\n",
      "auc 0.5958806818181818\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "for train_id, test_id in kf.split(x):\n",
    "    #print('train_index:%s , test_index: %s ' %(train_id, test_id))\n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "    threshold = 0.2\n",
    "\n",
    "    for epoch in range(100):\n",
    "        logits = net(g, x)\n",
    "        loss = criterion(logits.squeeze(dim=-1)[train_id], y[train_id])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        logits = net(g, x)\n",
    "        # print(logits)\n",
    "        y_pred = (logits >= threshold).int().squeeze(dim=-1)\n",
    "        acc = accuracy_score(y[test_id], y_pred[test_id])\n",
    "        #print(acc)\n",
    "        if best_acc < acc:\n",
    "            best_acc = acc\n",
    "            best_model = copy.deepcopy(net)\n",
    "\n",
    "    logits = best_model(g, x)\n",
    "    y_pred = (logits >= threshold).int().squeeze(dim=-1)\n",
    "\n",
    "    logits_list = logits[test_id][:, 0].data\n",
    "    index = sorted(range(len(logits_list)), key=lambda k: logits_list[k], reverse=True)\n",
    "    #print(test_id[index])\n",
    "\n",
    "\n",
    "    acc = accuracy_score(y[test_id], y_pred[test_id])\n",
    "    print(acc)\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y[test_id], y_pred[test_id])\n",
    "    #print(cm)\n",
    "\n",
    "    logits = logits[test_id]\n",
    "\n",
    "    acc = accuracy_score(y[test_id], y_pred[test_id])\n",
    "    print(\"final\", acc)\n",
    "\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, classification_report\n",
    "\n",
    "    y_true = y[test_id]\n",
    "    y_pred = y_pred[test_id]\n",
    "    # 1.计算混淆矩阵\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    conf_matrix = pd.DataFrame(cm, index=['0', '1'], columns=['0', '1'])  # 数据有5个类别\n",
    "\n",
    "    from sklearn import metrics\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, logits.detach().numpy())\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    #\n",
    "    # # 2.计算accuracy\n",
    "    # print('accuracy_score', accuracy_score(y_true, y_pred))\n",
    "    #\n",
    "    # # 3.计算多分类的precision、recall、f1-score分数\n",
    "    print(\"final\", acc)\n",
    "    print('precision', precision_score(y_true, y_pred))\n",
    "    print('recall', recall_score(y_true, y_pred))\n",
    "    print('f1-score', f1_score(y_true, y_pred))\n",
    "    print('auc', auc)\n",
    "    print('###')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
