{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'rna': 493},\n",
      "      num_edges={('rna', 'type1', 'rna'): 706, ('rna', 'type2', 'rna'): 708},\n",
      "      metagraph=[('rna', 'rna', 'type1'), ('rna', 'rna', 'type2')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_25740\\1248096087.py:35: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  name = x.loc[i][0]\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_25740\\1248096087.py:50: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  start = adj.loc[i][0]\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_25740\\1248096087.py:51: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  mid = adj.loc[i][1]\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_25740\\1248096087.py:52: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  end = adj.loc[i][2]\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model import HAN\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    \"\"\"\n",
    "    fix the random seed\n",
    "    :param seed: the random seed\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    return None\n",
    "\n",
    "setup_seed(0)\n",
    "\n",
    "# attribute\n",
    "name2id = {}\n",
    "id2name = {}\n",
    "\n",
    "x = pd.read_csv(\"data/features.csv\")\n",
    "\n",
    "for i in range(len(x)):\n",
    "    name = x.loc[i][0]\n",
    "    id2name[i] = name\n",
    "    name2id[name] = i\n",
    "\n",
    "x = x.iloc[:, 1:]\n",
    "x = x.to_numpy()\n",
    "\n",
    "# attribute\n",
    "\n",
    "adj = pd.read_csv(\"data/Network.csv\")\n",
    "\n",
    "max_id = x.shape[0]\n",
    "edges_1 = []\n",
    "edges_2 = []\n",
    "for i in range(len(adj)):\n",
    "    start = adj.loc[i][0]\n",
    "    mid = adj.loc[i][1]\n",
    "    end = adj.loc[i][2]\n",
    "\n",
    "    if 1:\n",
    "        try:\n",
    "            edges_1.append([name2id[start], name2id[mid]])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            edges_1.append([name2id[mid], name2id[start]])\n",
    "        except:\n",
    "            pass\n",
    "    if 1:\n",
    "        try:\n",
    "            edges_2.append([name2id[mid], name2id[end]])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            edges_2.append([name2id[end], name2id[mid]])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "label = pd.read_csv(\"data/label.csv\")\n",
    "\n",
    "y = np.zeros((x.shape[0], ))\n",
    "for i in range(len(label[\"node\"])):\n",
    "    try:\n",
    "        index = name2id[label[\"node\"].iloc[i]]\n",
    "        y[index] = label[\"label\"].iloc[i]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "y = torch.tensor(y).float()\n",
    "\n",
    "# x = np.concatenate([x, np.zeros((len(name2id)-x.shape[0], 5))], axis=0)\n",
    "\n",
    "x = torch.tensor(x).float()\n",
    "# print(x.shape)\n",
    "# print(len(id2name))\n",
    "# print(len(name2id))\n",
    "g = dgl.heterograph(\n",
    "    {\n",
    "        ('rna', 'type1', 'rna'): edges_1,\n",
    "        ('rna', 'type2', 'rna'): edges_2\n",
    "    }\n",
    ")\n",
    "\n",
    "# print(x.shape)\n",
    "print(g)\n",
    "\n",
    "\n",
    "# logits = rgcn_net(None, None)\n",
    "# y_pred = (logits >= 0.5).int().squeeze(dim=-1)\n",
    "\n",
    "# acc = accuracy_score(y[test_id], y_pred[test_id])\n",
    "# print(acc)\n",
    "\n",
    "# print(emb[\"inc_rna\"].shape)\n",
    "# print(emb[\"m_rna\"].shape)\n",
    "\n",
    "#\n",
    "# GCN\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "han_net = HAN(\n",
    "    meta_paths=[[\"type1\", \"type2\"], [\"type2\", \"type1\"]],\n",
    "    in_size=x.shape[1],\n",
    "    hidden_size=100,\n",
    "    out_size=1,\n",
    "    num_heads=[4],\n",
    "    dropout=0,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(han_net.parameters(), lr=1e-3)\n",
    "\n",
    "idx = list(range(x.shape[0]))\n",
    "random.shuffle(idx)\n",
    "idx = np.array(idx)\n",
    "\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "kf = KFold(n_splits=5,shuffle=False)  # 初始化KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35353535353535354\n",
      "[[14 63]\n",
      " [ 1 21]]\n",
      "final 0.35353535353535354\n",
      "final 0.35353535353535354\n",
      "precision 0.25\n",
      "recall 0.9545454545454546\n",
      "f1-score 0.39622641509433965\n",
      "auc 0.5923848878394333\n",
      "0.7777777777777778\n",
      "[[ 1 22]\n",
      " [ 0 76]]\n",
      "final 0.7777777777777778\n",
      "final 0.7777777777777778\n",
      "precision 0.7755102040816326\n",
      "recall 1.0\n",
      "f1-score 0.8735632183908045\n",
      "auc 0.5374713958810069\n",
      "0.6767676767676768\n",
      "[[19 30]\n",
      " [ 2 48]]\n",
      "final 0.6767676767676768\n",
      "final 0.6767676767676768\n",
      "precision 0.6153846153846154\n",
      "recall 0.96\n",
      "f1-score 0.7500000000000001\n",
      "auc 0.7714285714285715\n",
      "0.45918367346938777\n",
      "[[22 52]\n",
      " [ 1 23]]\n",
      "final 0.45918367346938777\n",
      "final 0.45918367346938777\n",
      "precision 0.30666666666666664\n",
      "recall 0.9583333333333334\n",
      "f1-score 0.4646464646464646\n",
      "auc 0.7609797297297297\n",
      "0.5306122448979592\n",
      "[[20 46]\n",
      " [ 0 32]]\n",
      "final 0.5306122448979592\n",
      "final 0.5306122448979592\n",
      "precision 0.41025641025641024\n",
      "recall 1.0\n",
      "f1-score 0.5818181818181819\n",
      "auc 0.7282196969696969\n"
     ]
    }
   ],
   "source": [
    "for train_id, test_id in kf.split(x):\n",
    "    #print('train_index:%s , test_index: %s ' %(train_id, test_id))\n",
    "    \n",
    "    optimizer = torch.optim.Adam(han_net.parameters(), lr=1e-3)\n",
    "    best_acc = 0\n",
    "    for epoch in range(100):\n",
    "        logits = han_net(g, x)\n",
    "        loss = criterion(logits.squeeze(dim=-1)[train_id], y[train_id])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        logits = han_net(g, x)\n",
    "        y_pred = (logits >= 0.2).int().squeeze(dim=-1)\n",
    "        acc = accuracy_score(y[test_id], y_pred[test_id])\n",
    "        #print(acc)\n",
    "        if best_acc < acc:\n",
    "            best_acc = acc\n",
    "            best_model = copy.deepcopy(han_net)\n",
    "\n",
    "\n",
    "    logits = best_model(g, x)\n",
    "    y_pred = (logits >= 0.2).int().squeeze(dim=-1)\n",
    "\n",
    "    logits_list = logits[test_id][:, 0].data\n",
    "    index = sorted(range(len(logits_list)), key=lambda k: logits_list[k], reverse=True)\n",
    "\n",
    "\n",
    "    acc = accuracy_score(y[test_id], y_pred[test_id])\n",
    "    print(acc)\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y[test_id], y_pred[test_id])\n",
    "    print(cm)\n",
    "\n",
    "    acc = accuracy_score(y[test_id], y_pred[test_id])\n",
    "    print(\"final\", acc)\n",
    "\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, classification_report\n",
    "\n",
    "    y_true = y[test_id]\n",
    "    y_pred = y_pred[test_id]\n",
    "\n",
    "    logits = logits[test_id]\n",
    "    #print('logits', logits)\n",
    "    from sklearn import metrics\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, logits.detach().numpy())\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    #\n",
    "    # # 2.计算accuracy\n",
    "    # print('accuracy_score', accuracy_score(y_true, y_pred))\n",
    "    #\n",
    "    # # 3.计算多分类的precision、recall、f1-score分数\n",
    "    print(\"final\", acc)\n",
    "    print('precision', precision_score(y_true, y_pred))\n",
    "    print('recall', recall_score(y_true, y_pred))\n",
    "    print('f1-score', f1_score(y_true, y_pred))\n",
    "    print('auc', auc)\n",
    "    #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
